{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://habrastorage.org/web/677/8e1/337/6778e1337c3d4b159d7e99df94227cb2.jpg\"/>\n",
    "## Специализация \"Машинное обучение и анализ данных\"\n",
    "</center>\n",
    "<center>Автор материала: программист-исследователь Mail.ru Group, старший преподаватель Факультета Компьютерных Наук ВШЭ Юрий Кашницкий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Capstone проект №1. Идентификация пользователей по посещенным веб-страницам\n",
    "<img src='http://i.istockimg.com/file_thumbview_approve/21546327/5/stock-illustration-21546327-identification-de-l-utilisateur.jpg'>\n",
    "\n",
    "# <center>Неделя 2. Подготовка и первичный анализ данных\n",
    "\n",
    "На второй неделе мы продолжим подготавливать данные для дальнейшего анализа и построения прогнозных моделей. Конкретно, раньше мы определили что сессия – это последовательность из 10 посещенных пользователем сайтов, теперь сделаем длину сессии параметром, и потом при обучении прогнозных моделей выберем лучшую длину сессии.\n",
    "Также мы познакомимся с предобработанными данными и статистически проверим первые гипотезы, связанные с нашими наблюдениями. \n",
    "\n",
    "**План 2 недели:**\n",
    " - Часть 1. Подготовка нескольких обучающих выборок для сравнения\n",
    " - Часть 2. Первичный анализ данных, проверка гипотез\n",
    "\n",
    "**В этой части проекта Вам могут быть полезны  следующие видеозаписи лекций курса \"Построение выводов по данным\":**\n",
    "\n",
    "   - [Доверительные интервалы для доли](https://www.coursera.org/learn/stats-for-data-analysis/lecture/3oi53/dovieritiel-nyie-intiervaly-dlia-doli)\n",
    "   - [Биномиальный критерий для доли](https://www.coursera.org/learn/stats-for-data-analysis/lecture/JwmBw/binomial-nyi-kritierii-dlia-doli)\n",
    "   - [Доверительные интервалы на основе бутстрепа](https://www.coursera.org/learn/stats-for-data-analysis/lecture/GZjW7/dovieritiel-nyie-intiervaly-na-osnovie-butstriepa)\n",
    "   \n",
    "**Кроме того, в задании будут использоваться библиотеки Python [glob](https://docs.python.org/3/library/glob.html), [pickle](https://docs.python.org/2/library/pickle.html), [itertools](https://docs.python.org/3/library/itertools.html) и класс [csr_matrix](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.sparse.csr_matrix.html) из scipy.sparse.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Задание:**</font> заполните код в этой тетрадке и выберите ответы в [веб-форме](https://docs.google.com/forms/d/13ZnT7w7foHD0uw0ynTtj7atdiCGvlltF8ThhbJCvLsc). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Подготовка нескольких обучающих выборок для сравнения\n",
    "\n",
    "Пока мы брали последовательности из 10 сайтов, и это было наобум. Давайте сделаем число сайтов в сессии параметром, чтоб в дальнейшем сравнить модели классификации, обученные на разных выборках – с 5, 7, 10 и 15 сайтами в сессии. Более того, пока мы брали по 10 сайтов подряд, без пересечения. Теперь давайте применим идею скользящего окна – сессии будут перекрываться. \n",
    "\n",
    "**Пример**: для длины сессии 10 и ширины окна 7 файл из 30 записей породит не 3 сессии, как раньше (1-10, 11-20, 21-30), а 5 (1-10, 8-17, 15-24, 22-30, 29-30). При этом в предпоследней сессии будет один ноль, а в последней – 8 нолей.\n",
    "\n",
    "Создадим несколько выборок для разных сочетаний параметров длины сессии и ширины окна. Все они представлены в табличке ниже:\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-031e\">session_length -&gt;<br>window_size <br></th>\n",
    "    <th class=\"tg-031e\">5</th>\n",
    "    <th class=\"tg-031e\">7</th>\n",
    "    <th class=\"tg-031e\">10</th>\n",
    "    <th class=\"tg-031e\">15</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">5</td>\n",
    "    <td class=\"tg-031e\">v</td>\n",
    "    <td class=\"tg-031e\">v</td>\n",
    "    <td class=\"tg-031e\">v</td>\n",
    "    <td class=\"tg-031e\">v</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">7</td>\n",
    "    <td class=\"tg-031e\"></td>\n",
    "    <td class=\"tg-031e\">v</td>\n",
    "    <td class=\"tg-031e\">v</td>\n",
    "    <td class=\"tg-031e\">v</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-031e\">10</td>\n",
    "    <td class=\"tg-031e\"></td>\n",
    "    <td class=\"tg-031e\"></td>\n",
    "    <td class=\"tg-031e\"><font color='green'>v</font></td>\n",
    "    <td class=\"tg-031e\">v</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Итого должно получиться 18 разреженных матриц – указанные в таблице 9 сочетаний параметров формирования сессий для выборок из 10 и 150 пользователей. При этом 2 выборки мы уже сделали в прошлой части, они соответствуют сочетанию параметров: session_length=10, window_size=10, которые помечены в таблице выше галочкой зеленого цвета (done)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте функцию *prepare_sparse_train_set_window*.\n",
    "\n",
    "Аргументы:\n",
    "- *path_to_csv_files* – путь к каталогу с csv-файлами\n",
    "- *site_freq_path* – путь к pickle-файлу с частотным словарем, полученным в 1 части проекта\n",
    "- *session_length* – длина сессии (параметр)\n",
    "- *window_size* – ширина окна (параметр) \n",
    "\n",
    "Функция должна возвращать 2 объекта:\n",
    "- разреженную матрицу *X_sparse* (двухмерная Scipy.sparse.csr_matrix), в которой строки соответствуют сессиям из *session_length* сайтов, а *max(site_id)* столбцов – количеству посещений *site_id* в сессии. \n",
    "- вектор *y* (Numpy array) \"ответов\" в виде ID пользователей, которым принадлежат сессии из *X_sparse*\n",
    "\n",
    "Детали:\n",
    "- Модифицируйте созданную в 1 части функцию *prepare_train_set*\n",
    "- Некоторые сессии могут повторяться – оставьте как есть, не удаляйте дубликаты\n",
    "- Замеряйте время выполнения итераций цикла с помощью *time* из *time*, *tqdm* из *tqdm* или с помощью виджета [log_progress](https://github.com/alexanderkuk/log-progress) ([статья](https://habrahabr.ru/post/276725/) о нем на Хабрахабре)\n",
    "- 150 файлов из *capstone_websites_data/150users/* должны обрабатываться за несколько секунд (в зависимости от входных параметров). Если дольше – не страшно, но знайте, что функцию можно ускорить. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "# отключим всякие предупреждения Anaconda\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from glob import glob\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy import stats\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_set(path_to_csv_files, sites, session_length=10, window_size=10):\n",
    "    files = glob(os.path.join(path_to_csv_files, '*.csv'))\n",
    "    files.sort()\n",
    "    columns = ['site' + str(i) for i in range(1, session_length + 1)]\n",
    "    columns.append('user_id')\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    for file in files:\n",
    "        user_id = int(os.path.basename(file)[4:-4])\n",
    "        lines = open(file).readlines()[1:]\n",
    "        counter = 0\n",
    "        sites_visited = [0] * session_length\n",
    "        buffer = []\n",
    "        for line in lines:\n",
    "            site_url = line.strip().split(',')[1]\n",
    "            if site_url not in sites:\n",
    "                print (\"Can't find site\", site_url)\n",
    "            else:\n",
    "                site = sites[site_url]\n",
    "            site_id = site[0]\n",
    "            sites_visited[counter] = site_id\n",
    "            counter += 1\n",
    "            if counter == session_length:\n",
    "                line = dict(zip(columns, sites_visited + [user_id]))\n",
    "                buffer.append(line)\n",
    "                counter -= window_size\n",
    "                sites_visited = sites_visited[window_size:] + [0] * window_size\n",
    "        while counter > 0:\n",
    "            line = dict(zip(columns, sites_visited + [user_id]))\n",
    "            buffer.append(line)\n",
    "            counter -= window_size\n",
    "            sites_visited = sites_visited[window_size:] + [0] * window_size\n",
    "        df = df.append(buffer, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sparse(X, columns_num):\n",
    "    counter = 0\n",
    "    values = []\n",
    "    for row in X:\n",
    "        sites = {}\n",
    "        for site_id in row:\n",
    "            if site_id:\n",
    "                sites[site_id] = sites.get(site_id, 0) + 1 \n",
    "        for site_id, value in sorted(sites.items()):\n",
    "            values.append((value, counter, site_id - 1))\n",
    "        counter += 1\n",
    "    site_counters, row_idxs, col_idxs = zip(*values)\n",
    "    return csr_matrix((site_counters, (row_idxs, col_idxs)),\n",
    "                      shape=(counter, columns_num), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sparse_train_set_window(path_to_csv_files, site_freq_path, \n",
    "                                    session_length=10, window_size=10):\n",
    "    with open(site_freq_path, 'rb') as site_freq_file:\n",
    "        sites_freq = pickle.load(site_freq_file)\n",
    "    df = prepare_train_set(path_to_csv_files, sites_freq,\n",
    "                           session_length, window_size)\n",
    "    X, y = df.iloc[:, :-1].values, df.iloc[:, -1].values\n",
    "    X_sparse = to_sparse(X, len(sites_freq))\n",
    "    return X_sparse, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примените полученную функцию с параметрами *session_length=5* и *window_size=3* к игрушечному примеру. Убедитесь, что все работает как надо.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_toy_s5_w3, y_s5_w3 = prepare_sparse_train_set_window(os.path.join(PATH_TO_DATA,'3users'), \n",
    "                                                       os.path.join(PATH_TO_DATA,'site_freq_3users.pkl'),\n",
    "                                       session_length=5, window_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site1 site2 site3 site4 site5 user_id\n",
       "0      1     2     2     3     2       1\n",
       "1      3     2     4     5     6       1\n",
       "2      5     6     7     8     1       1\n",
       "3      8     1     4     4     4       1\n",
       "4      4     4     0     0     0       1\n",
       "5      1     2     9     9     2       2\n",
       "6      9     2     0     0     0       2\n",
       "7     10     4     2     4     2       3\n",
       "8      4     2     4     4     6       3\n",
       "9      4     6    11    10    10       3\n",
       "10    10    10     4     2     0       3\n",
       "11     2     0     0     0     0       3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_csv_files = os.path.join(PATH_TO_DATA,'3users')\n",
    "site_freq_path = os.path.join(PATH_TO_DATA,'site_freq_3users.pkl')\n",
    "session_length=5\n",
    "window_size=3\n",
    "with open(site_freq_path, 'rb') as site_freq_file:\n",
    "    sites_freq = pickle.load(site_freq_file)\n",
    "df = prepare_train_set(path_to_csv_files, sites_freq,\n",
    "                       session_length, window_size)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 2, 0, 2, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 1, 0, 3, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 1, 0, 0, 0, 2, 1],\n",
       "        [0, 1, 0, 1, 0, 0, 0, 0, 0, 2, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_toy_s5_w3.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 2, 2, 3, 3, 3, 3, 3], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_s5_w3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Запустите созданную функцию 16 раз с помощью циклов по числу пользователей num_users (10 или 150), значениям параметра *session_length* (15, 10, 7 или 5) и значениям параметра *window_size* (10, 7 или 5). Сериализуйте все 16 разреженных матриц (обучающие выборки) и векторов (метки целевого класса – ID пользователя) в файлы `X_sparse_{num_users}users_s{session_length}_w{window_size}.pkl` и `y_{num_users}users_s{session_length}_w{window_size}.pkl`.**\n",
    "\n",
    "**Чтоб убедиться, что мы все далее будем работать с идентичными объектами, запишите в список *data_lengths* число строк во всех полученных рареженных матрицах (16 значений). Если какие-то будут совпадать, это нормально (можно сообразить, почему).**\n",
    "\n",
    "**На моем ноутбуке этот участок кода отработал за 26 секунд, хотя понятно, что все зависит от эффективности реализации функции *prepare_sparse_train_set_window* и мощности используемого железа. И честно говоря, моя первая реализация была намного менее эффективной (34 минуты), так что тут у Вас есть возможность оптимизировать свой код.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_sparse_10users_s15_w10.pkl\n",
      "X_sparse_10users_s15_w7.pkl\n",
      "X_sparse_10users_s10_w7.pkl\n",
      "X_sparse_10users_s7_w7.pkl\n",
      "X_sparse_10users_s15_w5.pkl\n",
      "X_sparse_10users_s10_w5.pkl\n",
      "X_sparse_10users_s7_w5.pkl\n",
      "X_sparse_10users_s5_w5.pkl\n",
      "X_sparse_150users_s15_w10.pkl\n",
      "X_sparse_150users_s15_w7.pkl\n",
      "X_sparse_150users_s10_w7.pkl\n",
      "X_sparse_150users_s7_w7.pkl\n",
      "X_sparse_150users_s15_w5.pkl\n",
      "X_sparse_150users_s10_w5.pkl\n",
      "X_sparse_150users_s7_w5.pkl\n",
      "X_sparse_150users_s5_w5.pkl\n",
      "CPU times: user 1min 28s, sys: 3.77 s, total: 1min 32s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import itertools\n",
    "\n",
    "data_lengths = []\n",
    "def pickle_to_file(filename, data):\n",
    "    with open(os.path.join(PATH_TO_DATA, filename), 'wb') as fl:\n",
    "        pickle.dump(data, fl, protocol=2)\n",
    "\n",
    "for num_users in [10, 150]:\n",
    "    for window_size, session_length in itertools.product([10, 7, 5], [15, 10, 7, 5]):\n",
    "        if window_size <= session_length and (window_size, session_length) != (10, 10):\n",
    "            csv_path = os.path.join(PATH_TO_DATA,'{}users'.format(num_users))\n",
    "            sites_path = os.path.join(PATH_TO_DATA,'site_freq_{}users.pkl'.format(num_users))\n",
    "            X_sparse, y = prepare_sparse_train_set_window(csv_path, sites_path,\n",
    "                                       session_length=session_length, window_size=window_size)\n",
    "            data_lengths.append(y.shape[0])\n",
    "            filename = 'X_sparse_{num_users}users_s{session_length}_w{window_size}.pkl'\n",
    "            filename = filename.format(num_users=num_users, session_length=session_length, window_size=window_size)\n",
    "            print(filename)\n",
    "            pickle_to_file(filename, X_sparse)\n",
    "            filename = 'y_{num_users}users_s{session_length}_w{window_size}.pkl'\n",
    "            filename = filename.format(num_users=num_users, session_length=session_length, window_size=window_size)\n",
    "            pickle_to_file(filename, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'> Вопрос 1. </font>Сколько всего уникальных значений в списке `data_lengths`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(data_lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Первичный анализ данных, проверка гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Считаем в DataFrame подготовленный на 1 неделе файл `train_data_10users.csv`. Далее будем работать с ним.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_data_10users.csv'), \n",
    "                       index_col='session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1  site2  site3  site4  site5  site6  site7  site8  site9  \\\n",
       "session_id                                                                  \n",
       "0               1      2      3      4      3      3      4      3      5   \n",
       "1               6      7      8      9      3     10     11     12     13   \n",
       "2              14      4     14     14     15     16      6     17     18   \n",
       "3              19     20     19     14     14     14     14     21     22   \n",
       "4              24     14     15     25     26     27     28     29     30   \n",
       "\n",
       "            site10  user_id  \n",
       "session_id                   \n",
       "0                3       31  \n",
       "1               14       31  \n",
       "2               14       31  \n",
       "3               23       31  \n",
       "4               29       31  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14061 entries, 0 to 14060\n",
      "Data columns (total 11 columns):\n",
      "site1      14061 non-null int64\n",
      "site2      14061 non-null int64\n",
      "site3      14061 non-null int64\n",
      "site4      14061 non-null int64\n",
      "site5      14061 non-null int64\n",
      "site6      14061 non-null int64\n",
      "site7      14061 non-null int64\n",
      "site8      14061 non-null int64\n",
      "site9      14061 non-null int64\n",
      "site10     14061 non-null int64\n",
      "user_id    14061 non-null int64\n",
      "dtypes: int64(11)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Распределение целевого класса:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128    2796\n",
       "39     2204\n",
       "207    1868\n",
       "127    1712\n",
       "237    1643\n",
       "33     1022\n",
       "50      802\n",
       "31      760\n",
       "100     720\n",
       "241     534\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['user_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посчитаем распределение числа уникальных сайтов в каждой сессии из 10 посещенных подряд сайтов.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_unique_sites = [np.unique(train_df.values[i, :-1]).shape[0] \n",
    "                    for i in range(train_df.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7     2308\n",
       "6     2197\n",
       "8     2046\n",
       "5     1735\n",
       "9     1394\n",
       "2     1246\n",
       "4     1163\n",
       "3      894\n",
       "10     651\n",
       "1      427\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(num_unique_sites).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a04f69ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(num_unique_sites).hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверьте с помощью QQ-плота и критерия Шапиро-Уилка, что эта величина распределена нормально**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'> Вопрос 2. </font>Распределено ли нормально число уникальных сайтов в каждой сессии из 10 посещенных подряд сайтов (согласно критерию Шапиро-Уилка)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14061,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques = pd.Series(num_unique_sites)\n",
    "uniques.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9546931982040405, 0.0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "scipy.stats.shapiro()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверьте гипотезу о том, что пользователь хотя бы раз зайдет на сайт, который он уже ранее посетил в сессии из 10 сайтов. Давайте проверим с помощью биномиального критерия для доли, что доля случаев, когда пользователь повторно посетил какой-то сайт (то есть число уникальных сайтов в сессии < 10) велика: больше 95% (обратите внимание, что альтернатива тому, что доля равна 95% –  одностороняя). Ответом на 3 вопрос в тесте будет полученное p-value.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'> Вопрос 3. </font>Каково p-value при проверке описанной гипотезы?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "has_two_similar = (np.array(num_unique_sites) < 10).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pi_val = stats.binom_test  ''' ВАШ КОД ЗДЕСЬ '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'> Вопрос 4. </font>Каков 95% доверительный интервал Уилсона для доли случаев, когда пользователь повторно посетил какой-то сайт (из п. 3)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wilson_interval = ''' ВАШ КОД ЗДЕСЬ '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('{} {}'.format(round(wilson_interval[0], 3),\n",
    "                                   round(wilson_interval[1], 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Постройте распределение частоты посещения сайтов (сколько раз тот или иной сайт попадается в выборке) для сайтов, которые были посещены как минимум 1000 раз.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "site_freqs = ''' ВАШ КОД ЗДЕСЬ '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' ВАШ КОД ЗДЕСЬ '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Постройте 95% доверительный интервал для средней частоты появления сайта в выборке (во всей, уже не только для тех сайтов, что были посещены как минимум 1000 раз) на основе bootstrap. Используйте столько же bootstrap-подвыборок, сколько сайтов оказалось в исходной выборке по 10 пользователям. Берите подвыборки из посчитанного списка частот посещений сайтов – не надо заново считать эти частоты. Учтите, что частоту появления нуля (сайт с индексом 0 появлялся там, где сессии были короче 10 сайтов) включать не надо. Округлите границы интервала до 3 знаков после запятой и запишите через пробел в файл *answer2_5.txt*. Это будет ответом на 5 вопрос теста.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color='red'> Вопрос 5. </font>Каков 95% доверительный интервал для средней частоты появления сайта в выборке?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bootstrap_samples(data, n_samples, random_seed=17):\n",
    "    np.random.seed(random_seed)\n",
    "    indices = np.random.randint(0, len(data), (n_samples, len(data)))\n",
    "    samples = data[indices]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stat_intervals(stat, alpha):\n",
    "    boundaries = np.percentile(stat, \n",
    "                 [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "    return boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' ВАШ КОД ЗДЕСЬ '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На 3 неделе мы займемся визуальным анализом данных и построением признаков."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
